# Python 爬虫进阶教程

> 本教程是「Python 爬虫入门教程」的延续，面向已掌握基础爬虫技术的学习者。教程将从工程化实践入手，逐步深入反爬虫对抗、浏览器自动化、登录认证等进阶主题，最终通过综合实战项目巩固所学知识。

## 适合人群

- 已完成入门教程 11 篇内容的学习者
- 了解 Python 异步编程基础（async/await）
- 希望提升爬虫工程化能力和反爬对抗能力的开发者

## 技术栈概览

| 类别 | 技术/工具 |
|------|----------|
| HTTP 客户端 | httpx (异步) |
| 浏览器自动化 | Playwright |
| 数据验证 | Pydantic |
| 日志系统 | loguru |
| 配置管理 | pydantic-settings |
| 代理管理 | 自研代理池 |
| 验证码识别 | ddddocr / 第三方打码平台 |
| 数据分析 | pandas / wordcloud / jieba |

---

## 教程目录

### [01_工程化爬虫开发规范](./01_工程化爬虫开发规范.md)

**学习目标：**
- 理解爬虫项目的工程化重要性
- 掌握 loguru 日志库的使用和日志分级策略
- 学会使用 pydantic-settings 进行配置管理
- 实现统一的异常处理和错误重试机制
- 了解项目目录结构的最佳实践

**核心内容：**
- **日志系统设计**：loguru 基本使用、日志分级（DEBUG/INFO/WARNING/ERROR）、日志轮转和持久化、异步日志写入
- **配置管理**：环境变量 vs 配置文件、pydantic-settings 实现配置验证、敏感信息的安全管理（.env 文件）、多环境配置切换
- **异常处理**：自定义异常类设计、全局异常捕获、重试装饰器实现（tenacity 库）、优雅降级策略
- **项目结构规范**：分层架构设计、模块划分原则、代码复用策略

**实战案例：** 将入门教程第 10 章的数据存储爬虫进行工程化改造，添加完善的日志系统、配置管理和异常处理机制。

---

### [02_反爬虫对抗基础_请求伪装](./02_反爬虫对抗基础_请求伪装.md)

**学习目标：**
- 理解常见的反爬虫检测手段
- 掌握 User-Agent 轮换策略
- 学会构造完整的请求头伪装
- 理解 Cookie 和 Session 的工作原理
- 实现基础的速率控制

**核心内容：**
- **反爬虫机制概述**：基于请求特征的检测、基于行为特征的检测、基于内容的检测、常见的封禁策略
- **User-Agent 策略**：真实浏览器 UA 收集、UA 随机轮换实现、移动端 vs 桌面端 UA 选择、fake-useragent 库的使用
- **请求头完整伪装**：必要的请求头字段（Accept、Accept-Language、Accept-Encoding 等）、Referer 的正确设置、请求头一致性维护、使用 curl_cffi 模拟浏览器指纹
- **速率控制**：固定延迟 vs 随机延迟、自适应速率调整、令牌桶算法实现、asyncio.Semaphore 控制并发数

**实战案例：** 爬取一个具有基础反爬的电商网站商品列表，实现完整的请求伪装和智能速率控制。

---

### [03_代理IP的使用与管理](./03_代理IP的使用与管理.md)

**学习目标：**
- 理解代理 IP 的工作原理和类型
- 学会评估代理 IP 的质量指标
- 掌握代理池的设计与实现
- 实现代理的自动检测和淘汰机制
- 理解隧道代理和 API 代理的使用

**核心内容：**
- **代理 IP 基础**：HTTP 代理 vs HTTPS 代理 vs SOCKS5 代理、透明代理 vs 匿名代理 vs 高匿代理、免费代理 vs 付费代理的取舍、代理提供商选择指南
- **代理池设计**（参考 MediaCrawler ProxyIpPool 设计）：代理池抽象接口设计、代理获取和存储、代理有效性检测、代理评分和淘汰机制、ProxyRefreshMixin 刷新机制
- **代理使用模式**：每次请求更换代理、按 IP 绑定代理（Session 粘性）、隧道代理的使用、API 提取型代理的封装
- **代理与异步请求集成**：httpx 设置代理、代理超时和重试策略、代理切换的优雅实现

**实战案例：** 实现一个完整的代理池管理类，支持从多个代理源获取代理、自动检测有效性、按需分配代理，并与爬虫主程序集成。

---

### [04_Playwright浏览器自动化入门](./04_Playwright浏览器自动化入门.md)

**学习目标：**
- 理解浏览器自动化的应用场景
- 掌握 Playwright 的安装和基本配置
- 学会页面导航、元素定位和交互操作
- 理解同步 API 和异步 API 的选择
- 掌握截图、PDF 导出等实用功能

**核心内容：**
- **Playwright 概述**：与 Selenium/Puppeteer 的对比、支持的浏览器（Chromium/Firefox/WebKit）、同步 vs 异步 API 选择、安装和浏览器驱动管理
- **页面基础操作**：Browser/Context/Page 三层模型、页面导航和等待策略、元素定位方式（CSS/XPath/Text/Role）、点击、输入、选择等交互操作
- **等待策略**（重要）：自动等待机制、waitForSelector / waitForLoadState、自定义等待条件、超时处理
- **页面内容提取**：获取元素文本和属性、执行 JavaScript 获取数据、拦截网络请求获取 API 数据、截图和 PDF 导出
- **浏览器配置**：有头模式 vs 无头模式、视口大小设置、用户数据目录持久化、代理设置

**实战案例：** 使用 Playwright 爬取一个需要 JavaScript 渲染的 SPA 单页应用，提取动态加载的数据列表。

---

### 05_Playwright进阶_反检测与性能优化

**学习目标：**
- 理解浏览器指纹检测原理
- 掌握 stealth.min.js 反检测注入
- 学会 CDP 模式的使用场景
- 掌握多浏览器实例管理和资源优化
- 实现浏览器上下文复用策略

**核心内容：**
- **浏览器指纹检测**：navigator 属性检测、WebGL/Canvas 指纹、WebDriver 特征检测、行为特征检测
- **stealth.js 反检测**（MediaCrawler 核心技术）：stealth.min.js 的工作原理、注入时机和方式、常见检测点的绕过、自定义反检测脚本
- **CDP 模式深入**：什么是 Chrome DevTools Protocol、标准模式 vs CDP 模式对比、连接已有浏览器实例、CDP 命令直接调用
- **性能优化**：禁用图片/CSS/字体加载、浏览器上下文复用、多页面并发管理、内存和资源监控、优雅关闭和资源释放
- **异常处理**：页面崩溃检测和恢复、超时重试策略、浏览器进程管理

**实战案例：** 使用 Playwright + stealth.js 爬取一个具有严格反爬检测的网站，对比有无反检测的效果差异。

---

### 06_登录认证_Cookie与Session管理

**学习目标：**
- 深入理解 Cookie 和 Session 的工作机制
- 掌握 Cookie 的提取、存储和注入
- 学会检测登录状态和 Cookie 有效性
- 实现 Cookie 的自动刷新机制
- 理解不同登录场景的处理策略

**核心内容：**
- **认证机制深入**：Cookie 的属性详解（Domain/Path/Expires/HttpOnly/Secure）、Session 的服务端实现、Token 认证的工作流程、多设备登录和踢出策略
- **Cookie 提取与存储**：从浏览器 DevTools 手动提取、使用 Playwright 自动提取、Cookie 的序列化格式（JSON/Netscape）、加密存储敏感 Cookie
- **Cookie 注入与使用**：httpx 中设置 Cookie、Playwright 中注入 Cookie、Cookie 的作用域管理、多账号 Cookie 轮换
- **登录状态管理**：登录状态检测方法、Cookie 过期检测、自动重新登录机制、登录状态持久化

**实战案例：** 实现一个完整的 Cookie 管理模块，支持 Cookie 的存储、加载、验证和自动刷新，可用于需要登录的爬虫场景。

---

### 07_登录认证_扫码与短信登录实现

**学习目标：**
- 理解扫码登录的技术原理
- 掌握使用 Playwright 实现扫码登录流程
- 理解短信验证码登录的实现方式
- 学会登录状态的监控和回调机制
- 实现多种登录方式的统一封装

**核心内容：**
- **扫码登录原理**（参考 MediaCrawler）：二维码生成和轮询机制、长轮询 vs WebSocket 状态推送、扫码状态（待扫描/已扫描/已确认/已过期）、登录成功后的 Cookie 获取
- **Playwright 实现扫码登录**：定位二维码元素、二维码截图和保存、终端显示二维码（可选）、轮询检测登录状态、登录成功后 Cookie 提取
- **短信验证码登录**：手机号输入和验证码发送、验证码输入（手动/API 接收）、滑块验证码的处理、登录失败的重试策略
- **登录模块封装**：登录方式抽象（工厂模式）、统一的登录接口设计、登录状态回调机制、异常处理和超时控制

**实战案例：** 参考 MediaCrawler 的登录实现，完成一个支持扫码登录和 Cookie 注入的双模式登录模块。

---

### 08_验证码识别与处理

**学习目标：**
- 了解常见验证码类型和破解思路
- 掌握图片验证码的 OCR 识别
- 学会滑块验证码的轨迹模拟
- 了解第三方打码平台的使用
- 理解验证码处理的合规边界

**核心内容：**
- **验证码类型概览**：图片字符验证码、数学运算验证码、滑块拼图验证码、点选验证码、行为验证码（如 reCAPTCHA）
- **图片验证码识别**：ddddocr 库的使用、图片预处理（二值化/降噪）、本地模型 vs 云端 API、识别率优化策略
- **滑块验证码处理**：缺口位置识别（OpenCV/图像差异）、人类拖拽轨迹模拟、速度和加速度曲线、Playwright 实现拖拽操作
- **第三方打码平台**：平台选择和价格对比、API 调用封装、超时和失败重试、成本控制策略
- **合规与伦理**：验证码绕过的法律边界、合理使用原则、替代方案考虑

**实战案例：** 实现一个验证码处理模块，支持图片验证码 OCR 识别和简单滑块验证码的自动处理。

---

### 09_数据清洗与预处理

**学习目标：**
- 掌握常见的数据清洗技术
- 学会使用正则表达式提取和清洗数据
- 理解数据去重和合并策略
- 掌握数据格式标准化方法
- 学会处理缺失值和异常值

**核心内容：**
- **数据清洗概述**：脏数据的常见类型、数据质量评估指标、清洗流程设计
- **文本清洗**：HTML 标签移除、空白字符处理、特殊字符清理、编码问题处理（Unicode 归一化）
- **正则表达式高级应用**：复杂模式匹配、命名分组提取、替换和转换、性能优化
- **数据去重与合并**：精确去重 vs 模糊去重、相似度计算（编辑距离/余弦相似度）、多数据源合并策略、冲突解决规则
- **数据标准化**：日期时间格式统一、数值单位换算、枚举值映射、字段命名规范

**实战案例：** 对前几章爬取的数据进行完整的清洗流程，包括文本清洗、格式标准化、去重处理，并输出干净的数据集。

---

### 10_数据分析与可视化

**学习目标：**
- 掌握 pandas 进行数据统计分析
- 学会生成词云展示文本数据
- 了解常用的数据可视化库（matplotlib/pyecharts）
- 实现简单的数据报告生成
- 理解爬取数据的分析价值

**核心内容：**
- **pandas 数据分析**：DataFrame 基础操作、数据聚合与分组统计、数据透视表、时间序列分析
- **词云生成**（参考 MediaCrawler）：jieba 中文分词、停用词过滤、wordcloud 库使用、自定义词云形状和配色
- **数据可视化**：matplotlib 基础图表（折线图/柱状图/饼图）、pyecharts 交互式图表、数据仪表盘设计、图表导出和嵌入
- **分析报告生成**：Markdown 报告模板、自动化报告生成、图表嵌入、定期报告推送

**实战案例：** 对爬取的社交媒体评论数据进行分析，生成词云、情感倾向统计图表，并输出一份完整的数据分析报告。

---

### 11_进阶综合实战项目

**学习目标：**
- 综合运用进阶教程所学的所有技术
- 实现一个完整的中等复杂度爬虫项目
- 掌握爬虫项目的完整开发流程
- 学会项目文档编写和部署

**核心内容：**
- **项目需求分析**：目标网站分析、数据需求定义、技术方案选型、风险评估
- **项目架构设计**：模块划分、类图设计、数据流设计、接口定义
- **核心功能实现**：登录模块（Cookie 注入 + 扫码登录）、爬取模块（Playwright + 反检测）、数据存储（多后端支持）、代理池集成、日志和监控
- **项目打包与部署**：代码结构整理、依赖管理（requirements.txt / pyproject.toml）、Docker 容器化部署、定时任务配置

**实战案例：** 完成一个类似 MediaCrawler 简化版的社交媒体数据采集工具，支持：
- 多种登录方式
- 反检测浏览器自动化
- 代理 IP 轮换
- 多格式数据存储
- 词云生成

---

## 源代码目录结构

```
源代码/爬虫进阶/
├── 01_工程化爬虫开发规范/
│   ├── config/
│   ├── logger_demo.py
│   ├── exception_demo.py
│   └── refactored_crawler/
├── 02_反爬虫对抗基础_请求伪装/
│   ├── ua_rotator.py
│   ├── headers_builder.py
│   └── rate_limiter.py
├── 03_代理IP的使用与管理/
│   ├── proxy_pool/
│   ├── proxy_checker.py
│   └── proxy_demo.py
├── 04_Playwright浏览器自动化入门/
│   ├── basic_operations.py
│   ├── wait_strategies.py
│   └── spa_crawler.py
├── 05_Playwright进阶_反检测与性能优化/
│   ├── stealth_demo.py
│   ├── cdp_mode.py
│   └── performance_optimization.py
├── 06_登录认证_Cookie与Session管理/
│   ├── cookie_manager.py
│   ├── session_demo.py
│   └── login_state_checker.py
├── 07_登录认证_扫码与短信登录实现/
│   ├── qrcode_login.py
│   ├── sms_login.py
│   └── login_factory.py
├── 08_验证码识别与处理/
│   ├── ocr_captcha.py
│   ├── slider_captcha.py
│   └── captcha_service.py
├── 09_数据清洗与预处理/
│   ├── text_cleaner.py
│   ├── deduplication.py
│   └── data_normalizer.py
├── 10_数据分析与可视化/
│   ├── pandas_analysis.py
│   ├── wordcloud_generator.py
│   └── chart_demo.py
└── 11_进阶综合实战项目/
    ├── config/
    ├── core/
    ├── login/
    ├── crawler/
    ├── store/
    ├── proxy/
    ├── analysis/
    └── main.py
```

---

## 教程特色

1. **与入门教程无缝衔接**：延续异步编程风格，逐步提升难度
2. **源于实战项目**：核心技术均来自 MediaCrawler 项目的生产实践
3. **每章都有代码**：提供完整可运行的示例代码和实战项目
4. **注重工程规范**：从第一章就强调代码质量和可维护性
5. **循序渐进**：从请求伪装到浏览器自动化，再到综合实战

---

## 学习建议

1. **按顺序学习**：每章内容都有前后依赖，建议按顺序学习
2. **动手实践**：每章的实战案例务必亲自完成
3. **阅读源码**：参考 MediaCrawler 项目源码加深理解
4. **遵守法规**：爬虫技术仅用于学习研究，请遵守相关法律法规
